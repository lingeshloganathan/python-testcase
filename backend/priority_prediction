"""
predict_priority_userstory.py

Given a specific UserStoryID (e.g., US-10):
 - find its commits from GitHub/local repo
 - extract changed functions/files
 - find matching tests
 - predict priorities using PPO model
 - remove duplicates and show final DataFrame
"""

import os
import re
import subprocess
import pandas as pd
import numpy as np
import gymnasium as gym
from stable_baselines3 import PPO
from sklearn.preprocessing import MinMaxScaler

# ====================================================
# Configuration
# ====================================================
USER_STORY_ID = "US-01"  # <-- change this to your story ID
REPO_PATH = r"D:\project-testcase"
MODEL_PATH = r"D:\project-testcase\backend\ppo_priority_gymnasium_model.zip"
TEST_RESULTS_PATH = r"D:\project-testcase\tests\results\test_results.csv"
OUTPUT_PATH = r"D:\project-testcase\backend\priority_userstory.csv"

# ====================================================
# 1ï¸âƒ£ Get Commits for the given UserStoryID
# ====================================================
def get_commits_for_story(repo_path, story_id):
    """Find all commits mentioning the UserStoryID."""
    os.chdir(repo_path)
    commits = subprocess.check_output(["git", "log", "--all", "--grep", story_id, "--pretty=%H"]).decode().splitlines()
    if not commits:
        raise ValueError(f"âŒ No commits found for {story_id}")
    print(f"ðŸ” Found {len(commits)} commits for {story_id}:")
    for c in commits:
        print("   ", c)
    return commits

def extract_changes(repo_path, commit_hash):
    """Extract changed files and functions for a given commit."""
    os.chdir(repo_path)
    changed_files = subprocess.check_output(
        ["git", "diff-tree", "--no-commit-id", "--name-only", "-r", commit_hash]
    ).decode().splitlines()

    diff_text = subprocess.check_output(["git", "show", commit_hash]).decode(errors="ignore")
    changed_functions = set(re.findall(r"def\s+(\w+)\s*\(", diff_text))

    return changed_files, changed_functions

commits = get_commits_for_story(REPO_PATH, USER_STORY_ID)

changed_files_total = set()
changed_functions_total = set()
for c in commits:
    f, funcs = extract_changes(REPO_PATH, c)
    changed_files_total.update(f)
    changed_functions_total.update(funcs)

print(f"\nðŸ“‚ Changed Files for {USER_STORY_ID}: {', '.join(changed_files_total)}")
print(f"âš™ï¸  Changed Functions: {', '.join(changed_functions_total)}\n")

# ====================================================
# 2ï¸âƒ£ Load Test Results
# ====================================================
tests = pd.read_csv(TEST_RESULTS_PATH, parse_dates=["Timestamp"])
tests["Status"] = tests["Status"].str.upper().fillna("PASSED")

# ====================================================
# 3ï¸âƒ£ Match Tests to Changed Code
# ====================================================
def compute_impact(row):
    test_name = str(row.get("Test Name", "")).lower()
    message = str(row.get("Message", "")).lower()
    score = 0

    if any(fn.lower() in test_name or fn.lower() in message for fn in changed_functions_total):
        score += 5
    if any(f.lower().split("/")[-1].replace(".py", "") in test_name for f in changed_files_total):
        score += 3
    if row["Status"] == "FAILED":
        score += 4
    return score

tests["ImpactScore"] = tests.apply(compute_impact, axis=1)
scaler = MinMaxScaler()
tests["ImpactScoreScaled"] = scaler.fit_transform(tests[["ImpactScore"]])

# ====================================================
# 4ï¸âƒ£ Define PPO Environment
# ====================================================
class PriorityEnv(gym.Env):
    def __init__(self, row):
        super().__init__()
        self.row = row
        self.observation_space = gym.spaces.Box(low=0, high=1, shape=(4,), dtype=np.float32)
        self.action_space = gym.spaces.Discrete(3)
        self.scaler = MinMaxScaler()

    def reset(self, *, seed=None, options=None):
        super().reset(seed=seed)
        fail = 1 if self.row["Status"] == "FAILED" else 0
        vec = np.array([
            self.row["ImpactScoreScaled"],
            fail,
            np.random.rand(),
            np.random.rand(),
        ], dtype=np.float32).reshape(1, -1)
        self.scaler.fit(np.vstack([vec, np.ones((1, 4))]))
        obs = self.scaler.transform(vec)[0]
        return obs, {}

    def step(self, action):
        reward = 0.0
        terminated, truncated = True, False
        return np.zeros(4, dtype=np.float32), reward, terminated, truncated, {}

# ====================================================
# 5ï¸âƒ£ Predict Priority Using PPO Model
# ====================================================
print("ðŸš€ Loading PPO model...")
model = PPO.load(MODEL_PATH)

predictions = []
for _, row in tests.iterrows():
    env = PriorityEnv(row)
    obs, _ = env.reset()
    action, _ = model.predict(obs, deterministic=True)
    priority = {0: "Low", 1: "Medium", 2: "High"}[int(action)]
    predictions.append(priority)

tests["Predicted Priority"] = predictions

# ====================================================
# 6ï¸âƒ£ Remove Duplicates (Keep Latest Unique Test ID)
# ====================================================
tests.sort_values("Timestamp", ascending=False, inplace=True)
tests_unique = tests.drop_duplicates(subset=["Test Case ID"], keep="first")

# Rank based on ImpactScore + Priority
priority_order = {"High": 3, "Medium": 2, "Low": 1}
tests_unique["PriorityValue"] = tests_unique["Predicted Priority"].map(priority_order)
tests_unique["FinalScore"] = tests_unique["ImpactScoreScaled"] * 0.6 + tests_unique["PriorityValue"] * 0.4

final_df = tests_unique.sort_values("FinalScore", ascending=False)

# ====================================================
# 7ï¸âƒ£ Output Results
# ====================================================
print("\n===== ðŸ§  Final Priority Table for", USER_STORY_ID, "=====")
print(final_df[["Test Case ID", "Test Name", "Status", "Predicted Priority", "ImpactScore", "FinalScore"]])

final_df.to_csv(OUTPUT_PATH, index=False)
print(f"\nâœ… Final priorities saved to {OUTPUT_PATH}")
